---
type: Project
title: Legalis
date: 2023-06-20
description: Machine Learning project about predicting the outcome of court cases in Germany.
images: ["/img/projects/legalis-thumbnail.png"]
focus: False
active: True
category: Machine Learning
tags: ["python", "university", "outcome prediction", "random forest", "BERT"]
link: https://ignitr.tech/legalis
github: https://github.com/LennardZuendorf/legalis
---

<Callout>
- University project focused on court case prediction
- Utilizes heavily processed German court case data
- Prediction models include Random Forest and BERT
</Callout>

### About the Project

Legalis is a university project for a machine learning and data science course. I wrote a paper at the University of Oslo about court case outcome prediction, and this is the continuation of that project.

I'm using bulk data from [openlegaldata](https://openlegaldata.io), which included about 250,000 cases, of which approximately 38,000 are usable for my purposes. Based on this data, I trained a random forest classifier to predict the outcome of court cases.

In the end, I achieved about 60% accuracy, which is not great but also not bad for this kind of problem.

### Features

Legalis offers several key features aimed at improving the prediction of court case outcomes:

- **Data Processing**: Utilizes extensive preprocessing of German court case data.
- **Prediction Models**: Employs Random Forest and BERT models for outcome prediction.
- **Model Training**: Trained on a substantial dataset to enhance prediction accuracy.
- **Outcome Extraction**: Uses ChatGPT to extract binary labels from case texts.

### Technology & Tools

<ProjectTech>
  <img
    src="https://img.shields.io/badge/python-3776AB?style=for-the-badge&logo=python&logoColor=white"
    alt="Python"
    className="rounded-sm"
  />
  <img
    src="https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white"
    alt="scikit-learn"
    className="rounded-sm"
  />
  <img
    src="https://custom-icon-badges.demolab.com/badge/transformers-6B7280?style=for-the-badge&logoColor=black&logo=transformers"
    alt="Transformers"
    className="rounded-sm"
  />
  <img
    src="https://img.shields.io/badge/chatGPT-74aa9c?style=for-the-badge&logo=openai&logoColor=white"
    alt="Chat GPT"
    className="rounded-sm"
  />
</ProjectTech>

I heavily rely on [ðŸ¤— Huggingface](https://huggingface.co/) features for my machine learning projects, especially for hosting datasets, models, and apps/spaces.

For prediction, I have trained and optimized a Random Forest classifier, a Naive Bayes classifier, and a BERT model for text classification.

I used ChatGPT to extract the outcome as a binary label for 2800 cases and trained the models on that. It works great for extracting specific information from longer texts (if you're willing to pay or have short texts).

### Future Plans

I plan to update this project to use a LLaMA2 or Mistral-based German language model for classification, as the BERT performance was already promising.